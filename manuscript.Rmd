---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"
    role:
      - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F, dpi=1200)

set.seed(123)
par(family = "Arial")
```

```{r pacman, eval=FALSE, include=FALSE}
#You need to run this chunk 1X in your system 
#install.packages("pacman")#Run this if you don't have pacman installed.
pacman::p_load(MOTE, tidyverse, psych, lavaan,kableExtra,gt,gtsummary, mirt,likert,kutils,semPlot,semTable,semTools,ggcorrplot,dlookr,qgraph,paran,EFA.MRFA,VIM,DiagrammeR,DiagrammeRsvg,ggplot2,cowplot,rsvg,questionr,magick, simsem,readxl, stringr,RColorBrewer,WrightMap, foreign,DT,SimDesign)
pacman::p_install_gh("jthomasmock/gtExtras")
pacman::p_install_gh("crsh/papaja")
pacman::p_install_gh("masiraji/tabledown")
pacman::p_install_gh("crsh/citr")

papaja::r_refs("references.bib")
#if you dont have LaTeX installed run the following lines
#install.packages("tinytex")
#tinytex::install_tinytex()
renv::snapshot()
```

```{r library, eval=FALSE, include=FALSE}
#This chunk holds code for calling the required packages

library(papaja) # devtools::install_github("crsh/papaja")
library(lavaan)
library(semPlot) #devtools::install_github('SachaEpskamp/semPlot',  dependencies = T)
library(semTools)
library(MOTE)
library(car)#reversecoding 
library(psych)
library(dlookr)
library(plyr)
library(tidyverse)
library(qgraph)
library(kableExtra)
library(paran) # Parallel analysis
library(EFA.MRFA) # Hull method
library(DiagrammeR) #devtools::install_github('rich-iannone/DiagrammeR')
library(DiagrammeRsvg) #For DiagrammeR
library(rsvg) #For DiagrammeR
library(ggcorrplot)
library(semTable)
library(magick)
library(mirt)
library(gtsummary)
library(gt)
library(gtExtras)
library(likert)
library(VIM) #Missing data
library(kutils)
library(simsem)
library(tabledown)
library(readxl)
library(koRpus)# stable release
library(koRpus.lang.en)
library(reshape)
library(ggsci)
renv::snapshot()
r_refs("references.bib")
```




---
nocite: |
  `r cite_r("references.bib")`
  
---


# Methods
```{r data, include=F}
# data <- readxl::read_excel("Processeddata/communication_data_n_582.xlsx")
# readr::write_rds(data, "Processeddata/communication_data_n_582.rds")
data <- readr::read_rds("Processeddata/communication_data_n_582.rds")

efa.data.full <- subset(data, Sample == "EFA")
cfa.data.full <- subset(data, Sample == "CFA"| Sample=="Validity")
validity.data.full <- subset(data, Sample == "Validity")


sem.data <- data[,c(2,6:66)]
efa.data <- subset(sem.data , Sample == "EFA")
efa.data <- efa.data[,c(2:24)]
efa.data <- na.omit(efa.data)

cfa.data<- subset(sem.data , Sample == "CFA"| Sample=="Validity")
cfa.data <- cfa.data[,c(2:24)]
cfa.data <- na.omit(cfa.data)

validity.data <- subset(sem.data , Sample == "Validity")
validity.data <-na.omit(validity.data)


irt.data <- sem.data[,2:24]


```

```{r descriptivrd, eval=FALSE, include=FALSE}
desc <- data[,c(3, 5,6)]
## Recoding desc$Sex
desc$Sex <- fct_recode(desc$Sex,
  "Boy" = "male",
  "Girl" = "female"
)
colnames(desc) <- c("Gender", "Social Status", "Age")

des_tab <- desc %>%
  tbl_summary(
    by = Gender,
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                     all_categorical() ~ "{n} ({p}%)"),
    type = list(Age ~ 'continuous'),
    digits = all_continuous() ~ 2,
    
    missing = "no"
    ) %>% add_overall() %>% bold_labels() %>% 
modify_header(label ~ "**Variable**")  %>%
  modify_caption("Demographic Characteristics") 
```

```{r gt-pic, include=F}
des_tab  %>%    # build gtsummary table
  as_gt() %>%             # convert to gt table
  gt::gtsave(             # save table as image
    filename = "Figures/demographics.png"
  )
```


```{r}

```



```{r}
reliability <- psych::alpha(com2, check.keys = T)
```


```{r}

gt.data <- na.omit(efa.data)

names(gt.data)[names(gt.data) == "RCS02"] <- "CS02"
names(gt.data)[names(gt.data) == "RCS05"] <- "CS05"

#Creating long data
gt.data.long <- as.data.frame(gather(gt.data, Items, value))
gt.data.long$value <- as.numeric(as.character(gt.data.long$value))


gt.data.tab <- gt.data.long %>% 
  group_by(Items) %>% 
  # calculate summary stats & create data for the histogram and density plot
  dplyr::summarise(
    nr = n(),
    mean = mean(value, na.rm = TRUE),
    med = median(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    hist_data = list(value),
    dens_data = list(value),
    .groups = "drop"
  ) %>% 
  gt() 


gt.likert <-  as.data.frame(gt.data)


#gt.likert <-  mutate(gt.likert, across(starts_with("ASQ"), ~unname(recod[.])))

gt.likert.Factor = as.data.frame(lapply(gt.likert,factor,
                                     ordered = T))


#get the items name
gt.items <- names(gt.likert.Factor) 
#Calculate percentage
gt.percentage <- kutils::likert(gt.likert.Factor, vlist = gt.items ) 

gt.percentage <- gt.percentage$table %>% 
  as.data.frame(.)

#data wrangling
labels <- c("never", "rarely","sometimes", "often", "always","Total")
as.data.frame(labels)

full.percentage <- cbind(labels,gt.percentage) #tables with labels  
full.percentage<- t(full.percentage ) #transpose
as.data.frame(full.percentage)
full.percentage1 <- full.percentage[-1,-6] #removing 1st row and total column
#full.percentage2 <- full.percentage1[, c(3, 4, 1, 2,5)]# rearranging
as.data.frame(full.percentage1)


colnames(full.percentage1) <- c("Never", "Rarely","Sometimes", "Often", "Always")

Items <- rownames(full.percentage1)
as.data.frame(Items)
full.percentage3 <- cbind(Items,full.percentage1)

full.percentage3 <- full.percentage3[order(Items),] 
full.percentage3 <- as.data.frame(full.percentage3[,-1]) 

full.percentage3 <- full.percentage3%>% 
  gt()


gt.table <- gt.data.tab$'_data'
gt.liket <- full.percentage3$"_data"


Table <-  cbind( gt.table, gt.liket )%>% 
  gt()%>% 
  # histogram and density plots
  gtExtras::gt_sparkline(
    hist_data,
    type = "histogram",
    line_color = "black", 
    fill_color = "#00A08799",
    bw = 1,
    same_limit = TRUE)%>%
  gtExtras::gt_sparkline(
    dens_data,
    type = "density",
    line_color = "black", 
    fill_color = "#E64B3599",
    bw = 0.75,
    same_limit = TRUE
  )%>%
  # format decimals
  fmt_number(columns = mean:sd, decimals = 1) %>%
  # header
  tab_header(
    title = md("**Communication**"),
    subtitle = md("Summary Descriptives")
  ) %>% 
  tab_footnote(
    footnote = md("**Histogram**"),
    locations = cells_column_labels(columns = hist_data)
  ) %>%
  tab_footnote(
    footnote = md("**Density**"),
    locations = cells_column_labels(columns = dens_data)
  ) %>% 
  #create groups of columns
  tab_spanner(
    label = "Items",
    columns = Items
  ) %>%
  tab_spanner(
    label = "Summary Statistics",
    columns = nr:sd
  ) %>%
  tab_spanner(
    label = "Graphics",
    columns = hist_data:dens_data
  )  %>%
  # change column names to appear in the table
  cols_label(
    Items = ("Items"),
    nr = ("n"),
    mean = ("Mean"),
    med = ("Median "),
    sd = (("SD")),
    hist_data = "Histogram",
    dens_data = "Density"
  ) %>%
  
  tab_spanner(
    label = "Response Pattern",
    columns = "Never":"Always"
  ) %>%
  # set alignment as per wish
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  opt_align_table_header(align = "left") %>%
  gtExtras::gt_plt_dot(
    mean,
    Items,
    palette = "ggthemes::fivethirtyeight")


gtsave(Table, "Figures/efa_communication.png",vwidth = 7000)
  
```




```{r ggplot2, include=F}
#This chunk holds code for creating ggplot2 based apatheme for plots.
apatheme=theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        #text=element_text(family = "Helvetica"),
        axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        plot.title = element_text(size = 15),
        legend.text = element_text(size = 15),
        legend.title=element_blank(),
        axis.line.x = element_line(color='black'),
        axis.line.y = element_line(color='black'),
        panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))

```



```{r EFAdata, include=FALSE}

#library(VIM)
missing <- VIM::aggr(efa.data, plot =T)

```

```{r EFAassumptions, include=FALSE}

#KMO test
KMO <- psych::KMO(efa.data) 

# Test of correlation matrix
bartlet <- psych::cortest.bartlett(efa.data, n =300)


#Histogram
#psych::multi.hist(EFA.data[,sapply(EFA.data, is.numeric)])

# Univariate normality

#creating normality function
shapiro_test_df <- function(df, bonf= TRUE, alpha= 0.05) {
  l <- lapply(df, shapiro.test)
  s <- do.call("c", lapply(l, "[[", 1))
  p <- do.call("c", lapply(l, "[[", 2))
  if (bonf == TRUE) {
    sig <- ifelse(p > alpha / length(l), "H0", "*")
  } else {
    sig <- ifelse(p > alpha, "H0", "*")
  }
  return(list(statistic= s,
              p.value= p,
              significance= sig,
              method= ifelse(bonf == TRUE, "Shapiro-Wilks test with Bonferroni Correction",
                             "Shapiro-Wilks test without Bonferroni Correction")))
}


Shapiro.efa <- shapiro_test_df(efa.data)


efa.normality.tab = matrix(nrow = 48, ncol = 2)
rownameprefix <- "Item"
rownamesufix <- seq(1:48)
my.item.names <- paste(rownameprefix,rownamesufix, sep = "" )
rownames(efa.normality.tab) <- my.item.names
colnames(efa.normality.tab) <- c("statistic", "p")

efa.normality.tab[,1] <- apa(Shapiro.efa$statistic,2,T)
efa.normality.tab[,2] <- apa(Shapiro.efa$p.value,2,T)

efa.normalityprefix <- efa.normality.tab[,1]
efa.normalitysufix <- Shapiro.efa$significance
efa.normality.stat <- paste(efa.normalityprefix,efa.normalitysufix, sep = "" )

# Multivariate Normality
mardia <- psych::mardia(efa.data, na.rm = T, plot =F)

# Descriptive Stats
Descriptives <- psych::describe(EFA.data)
alpha <- psych::alpha(EFA.data,check.keys=TRUE)
Item.total <- alpha$item.stats

Des.combined <- cbind(apa(Descriptives$mean,2,T), apa(Descriptives$sd,2,T), apa(Descriptives$skew,2,T),apa(Descriptives$kurtosis,2,T), efa.normality.stat,  apa(Item.total$r.cor,2,T))

colnames(Des.combined) = c("Mean", "SD", "Skew", "Kurtosis", "Shapiro-Wilk Statistics","Item-Total Correlation")
rownameprefix <- "Item"
rownamesufix <- seq(1:48)
my.names <- paste(rownameprefix,rownamesufix, sep = "" )
rownames(Des.combined) = (my.names)


decriptives <- tabledown::des.tab(efa.data)
```

## Item Analysis
`

```{r Cronbach, results='asis', width = 60}
Cron.bach <- psych::alpha(efa.data,check.keys=TRUE) 
Cron.bach$total %>% 
  knitr::kable(caption = "Alpha", digits = 2) %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)
Cron.bach$alpha.drop %>% 
  knitr::kable(caption = "Alpha value if item is dropped", digits = 2) %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)

Cron.bach$item.stats %>% 
  knitr::kable(caption = "Corrected Item total Correlation", digits = 2) %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)


low.r.corec <- (min(Cron.bach$item.stats$r.cor))  #minimum item total correlation
high.r.corec <- (max(Cron.bach$item.stats$r.cor))     # maximum item total correlation
  
```

```{r CorrMatrix, include=FALSE}
#Polychoric Correlation matrix

correlations <- psych::polychoric(efa.data)
upper <- correlations$rho[upper.tri(correlations$rho, diag = F)]

min.cor <- apa(min(abs(upper)),2,F) #minimum cor.coefficient of the matrix
max.cor <- apa(max(abs(upper)),2,F) # max. correlation coefficient of the matrix

determinets <- det(correlations$rho) 
# Calculating the percentage of correlations higher than .30

BigR = sum(correlations$rho >= abs(.30) & correlations$rho < abs(1.0), na.rm =T)/2 
totR = length(efa.data)*(length(efa.data)-1)/2
cor.per <- print (BigR/totR)*100
```


```{r corplot, include =F}
#This chunk holds code for plotting the correlation matrix

corplot <- ggcorrplot(correlations$rho, hc.order = TRUE, outline.col = "white", type = "lower", 
           ggtheme = ggplot2::theme_minimal(),tl.srt = 90,colors = c("#E64B35FF", "white", "#3C5488FF") )+
  theme( panel.grid.major = element_blank(),
         axis.text.x = element_text(size = 8),
         axis.text.y = element_text(size = 8),
         panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))
#p.mat <- cor_to_p(correlations$rho, 428, method = "polychoric")
#to show pvalue in the fig add p.mat=p.mat
ggsave("Figures/corplot.png",corplot, width = 6, height = 6, dpi = 600, bg ="white")

```

(ref:figCor) Inter item polychoric correlation coefficients for the 48 items. 4.9 % inter-item correlation coefficients were higher than .30

```{r figCor, out.height="150%",out.width="100%", fig.align= 'center', fig.cap='(ref:figCor)', results='asis', fig.align='center'}

knitr::include_graphics('Figures/corplot.png', dpi =600)

```


```{r ParallelEFA, include=FALSE}
#This chunk holds code for factor identification method : Horn
# Parallel analysis
Horn <- paran(correlations$rho, iterations=500, centile=0, quietly=FALSE,
           status=TRUE, all=FALSE, cfa=FALSE, graph=TRUE,
           color=TRUE, col=c("black","red","blue"),
           lty=c(1,2,3), lwd=1, legend=TRUE, 
           width=640, height=640, grdevice=png, seed=0, mat=NA, n=NA)


Adjusted.EV <- data.frame(Horn$AdjEv)
Adjusted.EV$type = c('Adjusted Ev')
Adjusted.EV$num = c(row.names(Adjusted.EV))
Adjusted.EV$num = as.numeric(Adjusted.EV$num)
colnames(Adjusted.EV) = c('eigenvalue', 'type', 'num')


Random.EV <- data.frame(Horn$RndEv)
Random.EV$type = c('Random EV')
Random.EV$num = c(row.names(Random.EV))
Random.EV$num = as.numeric(Random.EV$num)
colnames(Random.EV) = c('eigenvalue', 'type', 'num')


Unadjusted.EV <- data.frame(Horn$Ev)
Unadjusted.EV$type = c('Unadjusted EV')
Unadjusted.EV$num = c(row.names(Unadjusted.EV))
Unadjusted.EV$num = as.numeric(Unadjusted.EV$num)
colnames(Unadjusted.EV) = c('eigenvalue', 'type', 'num')



parallel = ggplot(Adjusted.EV, aes(x=num, y=eigenvalue, shape=type, color=type)) +
  #Add lines connecting data points
  geom_line(colour ='#DC000099')+
    #geom_line(data = Random.EV) +
  #geom_line(data = Unadjusted.EV)+
    #Add the data points.
  geom_point(size=1.5,colour ='#3C5488FF')+
  #geom_point(data = Random.EV, size=3)+
  #geom_point(data = Unadjusted.EV, size=3)+
  scale_y_continuous(name="Eigen Value", limits=c(0, 4), breaks=seq(0,4,1)) +
   #Label the x-axis 'Factor Number', and ensure that it ranges from 1-max # of factors, increasing by one with each 'tick' mark.
  scale_x_continuous(name='Factor Number (Parallel Analysis)', limits=c(0, 23),breaks=seq(0,23,4))+
    #Add vertical line indicating parallel analysis suggested max # of factors to retain
  geom_hline(yintercept=1, linetype = 'dashed') + apatheme +theme(,legend.position = "None") 
#text = element_text(size = 25)

```

```{r ScreePlot, include=FALSE}

#This chunk holds code for factor identification method : Scree Plot

Scree <- scree(correlations$rho,factors=TRUE,pc=TRUE,main="(B)",
      hline=NULL,add=F)


FA.Scree <- data.frame(Scree$fv)
FA.Scree$type = c('Factor Analysis')
FA.Scree$num = c(row.names(FA.Scree))
FA.Scree$num = as.numeric(FA.Scree$num)
colnames(FA.Scree) = c('eigenvalue', 'type', 'num')

PA.Scree <- data.frame(Scree$pcv)
PA.Scree$type = c('Principal Component Analysis')
PA.Scree$num = c(row.names(PA.Scree))
PA.Scree$num = as.numeric(PA.Scree$num)
colnames(PA.Scree) = c('eigenvalue', 'type', 'num')


scree.plot <-ggplot(FA.Scree, aes(x=num, y=eigenvalue,color=tye, shape=type))+
   geom_line(colour ='#DC000099')+
  #geom_line(data = PA.Scree)+ 
  geom_point(size=1.5,colour ='#3C5488FF')+
  #geom_point(data = PA.Scree, size=3)+
  scale_y_continuous(name="Eigen Value", limits=c(0, 5), breaks=seq(0,5,1)) +
  scale_x_continuous(name='Factor Number (Scree Plot)', limits=c(0, 20),breaks=seq(0,20,4))+
  geom_hline(yintercept=1, linetype = 'dashed') + apatheme +theme(legend.position = "None") 
#text = element_text(size = 25

```

```{r HullEFA, include=FALSE}
#This chunk holds code for factor identification method : Hull

# HULL
EFA.MRFA::hullEFA(efa.data,extr = "ULS", index_hull = "CAF", display = TRUE, graph = T,
        details = TRUE)
hull <- ggplot2::last_plot()
Hull <- hull+ ggtitle(NULL)+xlab("Factor Number (Hull Method)")+ylab("CAF")+ aes(color = '#DC000099')+geom_point(color ='#3C5488FF',size =1)+
  apatheme +theme(legend.position = "None") +scale_fill_identity()




```

```{r MAPefa, include=FALSE}
#This chunk holds code for factor identification method : MAP
#MAP
map <- psych::VSS(efa.data, rotate = "promax", fm = 'pa', n.obs =300 )
map.map <- as.data.frame(map$map)
colnames(map.map) <- "MAP Statistic"
map.statistics <- map$vss.stats[,c(1,2,5,6,7,10,11)]
full.map <- cbind(map.map,map.statistics)

write.csv(full.map, "Table_raw/map_stat.csv")
```
Scree plot, map and hull method ( Figure \@ref(fig:facIdFig)) suggested a one factor solution. Horn's parallel analysis [@hornRationaleTestNumber1965] with 500 iterations  indicated a two-factor solution. However, the minimum average partial (MAP) method (Table \@ref(tab:factormp)) [@velicerDeterminingNumberComponents1976] and Hull method [@lorenzo-sevaHullMethodSelecting2011] ( Figure \@ref(fig:facIdFig)) suggested a five-factor solution. As a result, we tested both five-factor and six-factor solutions.
```{r factors, include=F}
#This chunk holds code for compiled factor identification plots

factor <- cowplot::plot_grid(parallel, scree.plot,Hull, 
                   labels = "AUTO",
                   ncol=1, 
                  align = "v", 
                  label_fontfamily = "sans",
                  label_fontface = "plain")
ggsave("Figures/factors.png",factor, width = 5, height = 7, dpi = 600)
```

(ref:facIdFig) Factor Identification Methods (A) Parallel analysis  indicated the optimal number of factors were two. (B) Scree plot suggested One facor. (C) Hull method indicated 1 factors were required to balance the model fit and number of parameters.

```{r facIdFig, fig.align= 'center', fig.cap='(ref:facIdFig)',  warning=FALSE, results= 'asis'}

knitr::include_graphics("Figures/factors.png", dpi =800)

```



```{r EFA, include=FALSE}
fa.2F.1 <- fa(r=correlations$rho, nfactors = 2, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE)
AA <- print(fa.2F.1, cut = .3, digits = 3, sort = TRUE)


reduced.model.2F.1 <- dplyr::select(efa.data ,
                                    -c( CS21, CS11, CS23, CS09, RCS02,RCS05, CS16, CS01))

correlations.red.2F.1 <- polychoric(reduced.model.2F.1)

fa.2F.2 <- fa(r=correlations.red.2F.1$rho, nfactors = 2, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE)

BB <- print(fa.2F.2, cut = .3, digits = 3, sort = TRUE)

reduced.model.2F.2 <- dplyr::select(efa.data ,
                                    -c( CS21, CS11, CS23, CS09, RCS02,RCS05, CS16, CS01, CS03))

correlations.red.2F.2 <- polychoric(reduced.model.2F.2)


fa.2F.3 <- fa(r=correlations.red.2F.2$rho, nfactors = 2, fm= "pa",rotate ="varimax",
              residuals = TRUE, SMC = TRUE, max.iter = 500 )

CC <- print(fa.2F.3, cut = .3, digits = 3, sort = TRUE)

var1 <- CC$Vaccounted[2,1]*100
var2 <- CC$Vaccounted[2,2]*100

omega <- psych::omega(reduced.model.2F.2,2)

```


```{r EFA2f, include=FALSE}
fa.1F.1 <- fa(r=correlations$rho, nfactors = 1, fm= "pa",
              residuals = TRUE, SMC = TRUE)
AA <- print(fa.1F.1, cut = .3, digits = 3, sort = TRUE)


reduced.model.1F.1 <- dplyr::select(efa.data ,
                                    -c( CS16, RCS02, RCS05, CS01, CS09, CS23))

correlations.red.1F.1 <- polychoric(reduced.model.1F.1)

fa.1F.2 <- fa(r=correlations.red.1F.1$rho, nfactors = 1, fm= "pa",
              residuals = TRUE, SMC = TRUE)

BB <- print(fa.1F.2, cut = .3, digits = 3, sort = TRUE)

reduced.model.2F.2 <- dplyr::select(EFA.data ,
                                    -c( CS07, CS13, CS16, CS05, CS10, CS19, CS03, CS02, CS09, CS23, CS17, CS04))


correlations.red.2F.2 <- polychoric(reduced.model.2F.2)


fa.2F.3 <- fa(r=correlations.red.2F.2$rho, nfactors = 2, fm= "pa",rotate ="promax",
              residuals = TRUE, SMC = TRUE, max.iter = 500 )

CC <- print(fa.2F.3, cut = .3, digits = 3, sort = TRUE)




```



```{r CFAitems, include=FALSE }
#This chunk holds codes for 1st CFA 

model.1 <- "Communication =~ CS15 + CS21 +CS11 + CS20+ CS14+ CS19+ CS22+ CS12+ CS06+ CS07+ CS18+ CS08+        CS04+CS17+CS03+CS13+CS10" 


fit.1 <- cfa(model.1, data = cfa.data, ordered = names(cfa.data),estimator = "WLSMV") 

## Summary of Model 
cfa.sum.1 <- summary(fit.1, fit.measures =TRUE,standardized = TRUE,rsq =TRUE)


## Selected Fit measures 
fit.measures.1 <- fitmeasures (fit.1,c("gfi", "agfi", "nfi","rfi", 
                       "cfi","tli",
                       "rmsea", "rmsea.ci.lower", "rmsea.ci.upper","srmr"))


reliability1 <- semTools::reliability(fit.1)

```

```{r mod1, eval=FALSE, include=FALSE}
#This chunk holds codes for modification indices for 1st CFA
modfit.Cor.one <- modindices(fit.Cor.1, sort. = TRUE) 
modfit.Cor.one[modfit.Cor.one$mi>3.84,]
```

```{r cfaplot, include =F}
#This chunk holds codes to store CFA plot


png(filename="Manuscript.figures/CFAplot.png", 
    type="cairo",
    units="in", 
    width=12, 
    height=12, 
    pointsize=12, 
    res=1200)
semPaths (fit.1 , 
          what= "std",
          #"hide", #(hides coefficeits)
          #whatLabels = "std",
          intercepts = F,
          style ="OpenMx",
          #residScale = 6,
          theme = "colorblind",
          nCharNodes = 0,
          reorder =T,
          rotation =2,
          layout ="tree",
          cardinal = T,
          curvePivot =T,
          sizeMan =8,#items length
          sizeMan2 = 2,#items
          sizeLat = 12,#factors
          thresholds = FALSE,
          equalizeManifests =F,
          fade = FALSE,
          edge.label.cex = .8,
          #exoCov = T,
          centerLevels = T,
          #edge.color="black",
          label.scale=T,
          label.cex=1.2, #Font of factor and item name
          residuals=FALSE,
           #exoVar=FALSE,
          #fixedStyle=6, #Style of arrow (guide item)
          #freeStyle=1#Style of arrow (other item), #XKCD = TRUE
           
          )


dev.off()
```

```{r Shortcut Invariance}
invariance.data <- cfa.data.full[, c(3, 6:28)]
invariance.data <- na.omit(invariance.data )
library("semTools")
invariance.model <- measurementInvariance(model = model.1,
                                          data = invariance.data,
                                          group = "Gender",                                                                         estimator = "WLSMV",
                                          strict = T)
invariance.model[[1]] #configural Invariance
invariance.model[[2]] # loading, weak, metric
invariance.model[[3]] # intercept, strong, scaler
invariance.model[[4]] # residual, strict
invariance.model[[5]] # means, structural invariance
```

```{r figcfa, fig.cap = "Five Factor  Model of LEBA obtained by Confirmatory Factor Analysis. By allowing item pair 41 and 30 to covary their error variance our model attained the best fit.",  out.height='100%', warning=FALSE}

knitr::include_graphics("Figures/CFAplot.png", dpi =600)


```

## Measurement Invariance
```{r InvarianceAnalysis_data, include=FALSE}
#This chunk holds codes to prepare measurement invariance data.

invariance.data <- cfa.data.full[, c(3, 6:28)]
invariance.data <- na.omit(invariance.data )
mi.count <- invariance.data %>% 
  group_by(Gender) %>% 
  count() %>% 
  as.data.frame()
```





```{r Invariancedetail, include=FALSE}
#This chunk holds codes for measurement Invariance

model.1 <- "Communication =~ CS15 + CS21 +CS11 + CS20+ CS14+ CS19+ CS22+ CS12+ CS06+ CS07+ CS18+ CS08+        CS04+CS17+CS03+CS13+CS10" 

# Configural invariance ####
configural <- cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                  estimator = "WLSMV")

summary(configural, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)

fitmeasures (configural,c("gfi", "agfi", "nfi","rfi", 
                       "cfi","tli",
                       "rmsea", "rmsea.ci.lower", "rmsea.ci.upper","srmr"))

#Metric
weak <- cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                 
                  estimator = "WLSMV", 
            group.equal = "loadings")
            
summary(weak, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)


fitmeasures (weak,c("gfi", "agfi", "nfi","rfi", 
                       "cfi.scaled","tli.scaled",
                       "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled","srmr"))

First.comp <- compareFit (configural, weak)
summary(First.comp)



#Scaler
strong <- cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                  
                  estimator = "WLSMV", 
              group.equal = c("loadings", "intercepts"))
summary(strong, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)

Second.comp <- compareFit  (weak, strong)
summary(Second.comp)

#residual
strict <- cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                  
                  estimator = "WLSMV",  
              group.equal = c("loadings", "intercepts", "residuals")) 

summary(strict, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)
residual.fitm <- as.data.frame(fitmeasures (strict,c("gfi", "agfi", "nfi","rfi", "cfi","tli","rmsea", "srmr","aic")))

Third.comp <- compareFit(strict,strong)
summary(Third.comp)
#structural
structural <-cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                  
                  estimator = "WLSMV",  
                 group.equal = c("loadings", "intercepts", "residuals", "means","lv.variances","lv.covariances"))

summary(structural, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)
fitmeasures (structural,c("gfi", "agfi", "nfi","rfi", "cfi","tli","rmsea", "srmr","aic"))

fourth.comp <- compareFit  (structural,strict)
summary(fourth.comp)
comfit.par <- compareFit(configural, weak, strong, strict)
summary (comfit.par)

models <-  list("Configural" = configural, 
                "Metric" = weak, 
                "Scalar" = strong, 
                "Residual" = strict)



Invariance.table <- compareLavaan(models,
              nesting = "Configural > Metric > Scalar > Residual", 
              fitmeas = c("chisq", "df",  "cfi","tli","rmsea", "rmsea.ci.lower", "rmsea.ci.upper", "srmr" ),
              scaled = F,
              chidif = T, digits = 2)

colnames(Invariance.table) <- c("Chi-Square", "df", "CFI", "TLI", "RMSEA", "RMSEA 90% Lower CI", "RMSEA 90% Upper", "Chi-Square Difference", "df difference*", "p")


```

```{r InvarianceTab, results='asis'}
apa_table(Invariance.table, align = "c",  caption = "Measurment Invariance analysis on CFA sample (n=262) across native and non-native English speakers.", note = " a = Metric vs Configural; b = Scalar vs Metric; c = Residual vs Scalar; * =  df of model comparison", landscape = T, font_size = "footnotesize" )

```



```{r samplesizeIRT, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, results='hide', width=60}
set.seed(222)
m <-  23 # item number
n <- c(50, 75, 100, 150, 200, 300, 350) # sample size
design <- as.data.frame(n)


irtGenerate <- function(condition, fixed_objects = FALSE) {
n <- condition$n

a <- matrix(rlnorm(m,.2,.3))
diffs <- t(apply(matrix(runif(m*4, .3, 1), m), 1, cumsum))
diffs <- -(diffs - rowMeans(diffs))
diffs<- diffs + rnorm(m)
d <- diffs
dat <- simdata(a, d, n, itemtype = 'graded')
return(dat)
}

irtAnalyze <- function(condition, dat, fixed_objects = NULL) {
mod <- mirt(dat, 1, itemtype = 'graded', verbose = FALSE)
simpars <- coef(mod, simplify = TRUE, digits = Inf)$items
irtpars <- c(a = simpars[,1], d = simpars[,2])
return(irtpars)
}

irtSummarize <- function(condition, results,
fixed_objects = NULL) {
apop <- fixed_objects['alpha', ]
dpop <- fixed_objects['d', ]
simrmse <- RMSE(results, c(apop, dpop))
out <- c(RMSE = simrmse)
return(out)
}


simres <- runSimulation(design, replications = 100,
parallel = TRUE, generate = irtGenerate,
analyse = irtAnalyze, summarise = irtSummarize,
packages = c('mirt'))
simres


colind <- grep(".a.", colnames(simres))
sima <- as.data.frame(simres[, colind])
nvec <- as.numeric(simres$n)

meanRMSE <- rowMeans(sima)
names(meanRMSE) <- n
round(meanRMSE, 2)
matplot(nvec, log(sima), type = "l", col = 1, lty = 1,
ylab = "log(RMSE)", xlab = "sample size",
main = "Graded Response Model", xaxt = "n")
axis(1, at = nvec)
```

To gather more information on our retained one-factor solution, we sought Item Response Theory (IRT). IRT complements the conventional classical test theory-based analysis by gathering information on item discrimination and item difficulty. IRT judges an item's quality by providing item information in the light of participants' trait level ($\theta$). We gathered evidence on item quality as well as item fit, person fit and model by fitting a graded response model  in RStudio with the "mirt" package [@R-mirt]  [@R-mirt]. We did a Monte Carlo simulation using "SimDesign" package [@R-SimDesign]  with sample sizes varying from 50-350 and calculated average root mean squared error(RMSE) to estimate the optimal sample size for the graded response model with 23 items. The RMSE became stable for n = 200 to 300 (RMSE ranging between .25-.35). Our sample size within the estimated sample size for stability.


```{r}
irt.data <- na.omit(irt.data)
irt.data <- irt.data %>% 
  dplyr::select( CS03, CS04, CS06, CS07,CS08,CS10,CS11,    CS12, 
                 CS13,CS14,CS15,CS17, CS18, CS19, CS20 ,CS21, CS22)

fit <- mirt(irt.data, model = 1, itemtype = 'graded', 
               SE = TRUE, Se.type = 'MHRM',
               technical = list(NCYCLES = 10000))



# Model Parameters ####
params <- coef(fit, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
items <- data.frame(params$items)
se <- coef(fit, printSE = TRUE)

# Model Fit (degrees of freedom too low to check model fit)
model <- M2(fit)


#Item fit
item.fit<- itemfit(fit, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)

#Identifying Missfit items based on RMSEA Value
item_misfits <- subset(item.fit, RMSEA.S_X2 >= .06)

# Person Fit ####

personfit <- personfit(fit) 
personfit_model_misfits <- subset(personfit, Zh < -2)
rownames(personfit_model_misfits)
nrow(personfit_model_misfits)
hist(personfit$Zh, xlab = "Zh Statistics",main = "F1 Person Fit")
abline(v = -2, lwd = 2, lty = 2)


# Plots ####

OCC <- plot(fit, type = "trace", facet =T, main = "Communication Scale OCC")
info <- plot(fit, type = "infoSE", main = "Communication Scale")
iteminfo <- plot(fit, type = "infotrace", 
                    facet_items = T, main = "Communication Scale")





#conditional reliability
reliability <- plot(fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )

marginal.rel <- marginal_rxx(fit)

#scale characteristics curve
scale <- plot(fit, type = 'score', theta_lim = c(-6, 6), main = "")

#-3<b<3
#.5<a<2; baker p12
```



```{r OCC, include=F}
ggicc <- function(model, item, theta){
  Theta <- matrix(seq(-theta,theta, by = .1))
  iteminfo <- mirt::extract.item(model, item)
  P <-mirt::probtrace(x=iteminfo , Theta=Theta  )
  icc <- data.frame(P = P, Theta = Theta)
  colnames(icc) <- c(paste("P", 1:ncol(P), sep=''), "Theta")
  icc2<- reshape(icc, direction='long', varying = paste("P", 1:ncol(P), sep=''), v.names = 'P',
                 times = paste("P", 1:ncol(P), sep=''))
  plot <- ggplot2::ggplot(icc2,aes(Theta,P, col =time))+geom_line()+xlab(expression(theta)) + 
    ylab(expression(P(theta)))+ theme(legend.title=element_blank())
  return(plot)
  
}

library(ggsci)

item03 <- ggicc(fit,1,6)+apatheme+ggtitle("item03")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item04 <- ggicc(fit,2,6)+apatheme+ggtitle("item04")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))



item06 <- ggicc(fit,3,6)+apatheme+ggtitle("item06")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item07 <- ggicc(fit,4,6)+apatheme+ggtitle("item07")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item08 <- ggicc(fit,5,6)+apatheme+ggtitle("item08")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))




item10 <- ggicc(fit,6,6)+apatheme+ggtitle("item10")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item11 <- ggicc(fit,7,6)+apatheme+ggtitle("item11")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))
ggsave("Figures/ideal_icc.png",item11 , width = 12, height = 8, dpi = 600, bg = "white")


item12 <- ggicc(fit,8,6)+apatheme+ggtitle("item12")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item13 <- ggicc(fit,9,6)+apatheme+ggtitle("item013")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item14 <- ggicc(fit,10,6)+apatheme+ggtitle("item14")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item15 <- ggicc(fit,11,6)+apatheme+ggtitle("item15")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))



item17 <- ggicc(fit,12,6)+apatheme+ggtitle("item17")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item18 <- ggicc(fit,13,6)+apatheme+ggtitle("item18")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item19 <- ggicc(fit,14,6)+apatheme+ggtitle("item19")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item20 <- ggicc(fit,15,6)+apatheme+ggtitle("item20")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item21 <- ggicc(fit,16,6)+apatheme+ggtitle("item21")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))

item22 <- ggicc(fit,17,6)+apatheme+ggtitle("item22")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))



ICC <- cowplot::plot_grid(item03, item04, item06, item07, item08, 
                   item10, item11, item12, item13, item14, item15,  item17, item19,
                   item20, item21, 
                      labels = "AUTO",
                     ncol=4,  
                    label_size = 15, 
                     align = "v")


ggsave("Figures/ICC.png",ICC , width = 12, height = 12, dpi = 600, bg = "white")




```



```{r item-plots, inclide =F}


iteminfo <- plot(fit, type = "infotrace",which.item =2)

itemplot.01 <- tabledown::ggiteminfo(fit,1,6)+apatheme+
  ggtitle(" Item03")+theme(legend.position = "none")+
  labs(y = "Item Information")+
  scale_color_npg()+geom_hline(yintercept = .20, colour ="red")+geom_area(fill ="palegreen4" )+
  xlab(expression(theta))+ ylab(expression(I(theta)))


itemplot.02 <- tabledown::ggiteminfo(fit,2,6)+apatheme+
  ggtitle(" Item04")+theme(legend.position = "none")+
  labs(y = "Item Information")+
  scale_color_npg()+geom_hline(yintercept = .20, colour ="red")+geom_area(fill ="palegreen4" )+
  xlab(expression(theta))+ ylab(expression(I(theta)))




good.info <- cowplot::plot_grid( item6.iic1, item7.iic1, item11.iic1, item12.iic1, item14.iic1, item15.iic1 , item18.iic1, item19.iic1, item20.iic1, item21.iic1, item22.iic1, 
                                 labels = "AUTO",ncol=3, label_size = 15,align = "v")


ggsave("Figures/good.info.png",good.info, width = 12, height = 8, dpi = 600, bg = "white")

test.info <- tabledown::ggtestinfo(irt.data,fit)+ apatheme+geom_line(colour = "black", size=1.5)+geom_area(fill ="palegreen4" )+geom_vline(xintercept = -3, colour ="black")+
  geom_vline(xintercept = .5, colour ="black")
library(plotly)
info.p <- plotly::ggplotly(test.info)

```



```{r IRT2, include}

irt.2 <- dplyr::select(EFA.data, -c(CS01,CS02,CS03,CS04, CS05,CS08, CS09, CS10, CS13, CS16, CS17,CS23))



fit2 <- mirt(irt.2, model = 1, itemtype = 'graded', 
               SE = TRUE, Se.type = 'MHRM',
               technical = list(NCYCLES = 10000))


occ <- plot(fit2, facet =T, type= "trace")


# Model Parameters ####
params2 <- coef(fit2, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
items2 <- data.frame(params2$items)
se2 <- coef(fit2, printSE = TRUE)

# Model Fit (degrees of freedom too low to check model fit)
model2 <- as.data.frame(M2(fit2))


#Item fit
item.fit2<- itemfit(fit2, fit_stats = c("S_X2",  "infit"),
                                  impute=10)

#Identifying Missfit items based on RMSEA Value
item_misfits2 <- subset(item.fit2, RMSEA.S_X2 >= .06)


## Creating IRT table
item.fit3 <- item.fit2[,-c(1,2,4)] 
colnames(item.fit3) <- c("Outfit", "Infit", "S-Chi-square", "df", "RMSEA", "p")

IRT.details <- cbind(items2 ,item.fit3)

IRT.details <- IRT.details %>% 
 dplyr::mutate_if(is.numeric, round, digits=3)

IRT.details <- tibble::rownames_to_column(IRT.details, "Items")
#write_csv(IRT.details, "table_raw/IRT_parameters.csv")

#-3<b<3
#.5<a<2; baker p12

mean.discrimination <- mean(IRT.details$a)
sd.discrimination <- sd(IRT.details$a)
range.descrimination <- range(IRT.details$a)

cat.prob <- IRT.details[,c(3:6)]
cat.prob.long <- reshape::melt(cat.prob)
range.difficulty <- range(cat.prob.long$value)

range.outfit <-  range(IRT.details$Outfit)
range.infit <-  range(IRT.details$Infit)
range.rmsea <- range(IRT.details$RMSEA)


# Person Fit ####
personfit2 <- personfit(fit2) 
personfit_model_misfits2 <- subset(personfit2, Zh < -2)
rownames(personfit_model_misfits2)
nrow(personfit_model_misfits2)


person <- ggplot(personfit2, aes(x=Zh)) + geom_histogram(binwidth=.5,col=I("black"),fill="palegreen4")+geom_vline(xintercept = -2)+
  labs( y="Number of Participants", x = "Zh Statistics")+apatheme + xlim(-4,2)+
   scale_y_continuous(limits = c(0, 40), expand = expand_scale(mult = c(0, 0.1)))


annotation.1 <- data.frame(
   x = (-3.1),
   y = (20),
   label = ("Most of the participants
        are within the guidline")
)

per.anno <-person + geom_label(data=annotation.1, aes( x=x, y=y, label=label),                 , 
           color="orange", 
           size=5 , angle=45, fontface="bold" )


ggsave("Figures/person.png",per.anno , width = 12, height = 8, dpi = 600, bg = "white")

# Plots ####

OCC2 <- plot(fit2, type = "trace", facet =T, main = "Communication Scale OCC")
info2 <- plot(fit2, type = "infoSE", main = "Communication Scale")
iteminfo2 <- plot(fit2, type = "infotrace", 
                    facet_items = T, main = "Communication Scale")

##Test Info
info <- tabledown::ggtestinfo(irt.2, fit2)+apatheme+geom_line(colour = "black", size=1.5)+geom_area(fill ="palegreen4" )+geom_vline(xintercept = -3, colour ="black")+
  geom_vline(xintercept = .5, colour ="black")
library(plotly)
info.p <- plotly::ggplotly(info)

annotation <- data.frame(
   x = c(-4.2,1.5),
   y = c(4.5,4.3),
   label = c("Theta = -3", "Theta =.5")
)

info.anno <- info + geom_label(data=annotation, aes( x=x, y=y, label=label),
           color="orange", 
           size=7 , angle=45, fontface="bold" )

ggsave("Figures/TIC.png",info.anno  , width = 12, height = 8, dpi = 600, bg = "white")


#conditional reliability
library(latticeExtra)
library(directlabels)
font.settings <- list(
  font = 1,
  cex = 6,
  fontfamily = "sans")

apa.latice  <- list(
  par.xlab.text = font.settings,
  par.ylab.text = font.settings,
  axis.text = font.settings,
  sub.text = font.settings,
  add.text = font.settings)





reliability.focused <- plot(fit2, type = 'rxx', theta_lim = c(-4, 2), 
      main="Conditional Reliability Plot", par.settings=c(apa.latice),col.line = "#E69F00",lwd = 3.5 )






marginal.rel2 <- marginal_rxx(fit2)

#scale characteristics curve
scale2 <- plot(fit2, type = 'score', theta_lim = c(-6, 6), main = "")



```

```{r conrel-print, include=F}
##
png(filename="Figures/conrel.png", 
    type="cairo",
    units="in", 
    width=12, 
    height=8, 
    pointsize=12, 
    res=300)
plot(fit2, type = 'rxx', theta_lim = c(-6, 6), 
      main="", par.settings=c(apa.latice),col.line = "#E69F00",lwd = 3.5, cex =2.5 )+
  layer(panel.abline(v = -4, colour = "red",panel=panel.filled_smooth))+
  layer(panel.abline(v = 1.5))

dev.off()
```






Marginal reliability is based on the true score model (Lord & Novick, 1968) and is an estimate of the overall reliability of a test based on the average conditional standard errors. Often it is close in value to coefficient alpha (and sometimes it may even be identical). Alpha provides a lower estimate of marginal reliability.



```{r dif}
library("lordif")
gender <- as.data.frame(data$Gender)
colnames(gender) <- "Gender"
gender$Gender <- as.factor(gender$Gender)
irt.data <- na.omit(irt.data)
communication <- sem.data[,c(2:24)]
dif.data <- cbind(gender, communication)
dif.data <- na.omit(dif.data)
dif.data.full <- as.data.frame(dif.data)
DIF <- lordif(as.data.frame(irt.data), group = dif.data.full$Gender, criterion = "Chisqr")

DIF$stats[,1:5]
plot(DIF)
```


## Participants

## Material

## Procedure

## Data analysis
We used `r cite_r("references.bib")` for all our analyses.


# Results

# Discussion


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
